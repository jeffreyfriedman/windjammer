# v0.24.0 - Full Salsa LSP Integration Plan

**Date**: October 12, 2025  
**User Request**: "I want full Salsa implementation in 0.24.0"  
**Priority**: HIGH  
**Status**: Planning Phase

---

## Executive Summary

Salsa provides incremental computation for LSPs, enabling:
- **10-100x faster** re-parsing (1-5ms vs 10-100ms)
- **Cross-file analysis** (rename across files, find all references)
- **Smart caching** (automatic memory management and invalidation)
- **Professional-grade performance** (on par with rust-analyzer)

**Estimated Effort**: 2-3 weeks full implementation

---

## Phase 1: Foundation (Week 1, Days 1-3)

### 1.1 Add Salsa Dependency

**File**: `crates/windjammer-lsp/Cargo.toml`

```toml
[dependencies]
salsa = "0.17"  # Latest stable version
```

### 1.2 Design Query Structure

**File**: `crates/windjammer-lsp/src/database.rs` (new)

```rust
use salsa::Database;
use tower_lsp::lsp_types::Url;
use std::sync::Arc;

// Core database that stores all memoized data
#[salsa::database(
    LanguageStorage,
    DiagnosticsStorage,
    SemanticTokensStorage
)]
pub struct WindjammerDatabase {
    storage: salsa::Storage<Self>,
}

impl salsa::Database for WindjammerDatabase {}

// Query group for language analysis
#[salsa::query_group(LanguageStorage)]
pub trait LanguageQueries: salsa::Database {
    // Input: source text (changes trigger recomputation)
    #[salsa::input]
    fn source_text(&self, uri: Url) -> Arc<String>;
    
    // Derived: parse tree (memoized, only recomputes if source changes)
    fn parse(&self, uri: Url) -> Arc<windjammer::parser::Program>;
    
    // Derived: imported files (tracks dependencies)
    fn imports(&self, uri: Url) -> Arc<Vec<Url>>;
    
    // Derived: type checking results
    fn type_check(&self, uri: Url) -> Arc<TypeCheckResult>;
}

// Query group for diagnostics
#[salsa::query_group(DiagnosticsStorage)]
pub trait DiagnosticsQueries: LanguageQueries {
    // Derived: diagnostics (auto-recomputes when parse or typecheck changes)
    fn diagnostics(&self, uri: Url) -> Arc<Vec<Diagnostic>>;
}

// Query group for semantic tokens
#[salsa::query_group(SemanticTokensStorage)]
pub trait SemanticTokensQueries: LanguageQueries {
    // Derived: semantic tokens (memoized)
    fn semantic_tokens(&self, uri: Url) -> Arc<Vec<SemanticToken>>;
}
```

### 1.3 Implement Query Functions

**File**: `crates/windjammer-lsp/src/database.rs` (continued)

```rust
// Parse query: memoized parsing
fn parse(db: &dyn LanguageQueries, uri: Url) -> Arc<windjammer::parser::Program> {
    let source = db.source_text(uri);
    let program = windjammer::parser::parse(&source);
    Arc::new(program)
}

// Imports query: track file dependencies
fn imports(db: &dyn LanguageQueries, uri: Url) -> Arc<Vec<Url>> {
    let program = db.parse(uri);
    let mut imports = Vec::new();
    
    // Extract import statements
    for item in &program.items {
        if let windjammer::parser::Item::Import(import) => {
            let import_uri = resolve_import(&uri, &import.path);
            imports.push(import_uri);
        }
    }
    
    Arc::new(imports)
}

// Type check query: depends on parse and imports
fn type_check(db: &dyn LanguageQueries, uri: Url) -> Arc<TypeCheckResult> {
    let program = db.parse(uri.clone());
    let imports = db.imports(uri.clone());
    
    // Load imported types
    let mut imported_types = HashMap::new();
    for import_uri in imports.iter() {
        let import_program = db.parse(import_uri.clone());
        // Extract exported types
        for item in &import_program.items {
            // ... collect types ...
        }
    }
    
    // Type check this file
    let result = windjammer::type_checker::check(&program, &imported_types);
    Arc::new(result)
}

// Diagnostics query: depends on type check
fn diagnostics(db: &dyn DiagnosticsQueries, uri: Url) -> Arc<Vec<Diagnostic>> {
    let type_result = db.type_check(uri.clone());
    let parse_result = db.parse(uri);
    
    let mut diagnostics = Vec::new();
    
    // Parse errors
    for error in &parse_result.errors {
        diagnostics.push(error_to_diagnostic(error));
    }
    
    // Type errors
    for error in &type_result.errors {
        diagnostics.push(error_to_diagnostic(error));
    }
    
    Arc::new(diagnostics)
}

// Semantic tokens query: depends on parse and type check
fn semantic_tokens(db: &dyn SemanticTokensQueries, uri: Url) -> Arc<Vec<SemanticToken>> {
    let program = db.parse(uri.clone());
    let types = db.type_check(uri);
    
    let tokens = generate_semantic_tokens(&program, &types);
    Arc::new(tokens)
}
```

**Deliverable**: Salsa database compiles and basic queries work

---

## Phase 2: Integration (Week 1, Days 4-5)

### 2.1 Update Server Structure

**File**: `crates/windjammer-lsp/src/server.rs`

```rust
use crate::database::WindjammerDatabase;

pub struct WindjammerLanguageServer {
    // Replace simple caches with Salsa database
    db: Arc<Mutex<WindjammerDatabase>>,
    
    // Keep for tracking which files are open
    open_documents: DashMap<Url, ()>,
}

impl WindjammerLanguageServer {
    pub fn new() -> Self {
        Self {
            db: Arc::new(Mutex::new(WindjammerDatabase::default())),
            open_documents: DashMap::new(),
        }
    }
}
```

### 2.2 Update Document Change Handler

```rust
async fn did_change(&self, params: DidChangeTextDocumentParams) {
    let uri = params.text_document.uri;
    let text = params.content_changes[0].text.clone();
    
    // Update Salsa input
    let mut db = self.db.lock().unwrap();
    db.set_source_text(uri.clone(), Arc::new(text));
    drop(db);  // Release lock
    
    // Salsa automatically invalidates dependent queries!
    // No need to manually trigger re-parsing or re-type-checking
    
    // Publish diagnostics (will recompute only what changed)
    self.publish_diagnostics(uri).await;
}
```

### 2.3 Update Diagnostic Handler

```rust
async fn publish_diagnostics(&self, uri: Url) {
    let db = self.db.lock().unwrap();
    
    // This query will be fast if nothing changed!
    let diagnostics = db.diagnostics(uri.clone());
    
    drop(db);
    
    // Send to client
    self.client.publish_diagnostics(uri, diagnostics.to_vec(), None).await;
}
```

### 2.4 Update Other LSP Handlers

```rust
async fn hover(&self, params: HoverParams) -> Result<Option<Hover>> {
    let uri = params.text_document_position_params.text_document.uri;
    let position = params.text_document_position_params.position;
    
    let db = self.db.lock().unwrap();
    let program = db.parse(uri.clone());
    let types = db.type_check(uri);
    drop(db);
    
    // Find symbol at position and return type info
    // ... hover logic ...
}

async fn semantic_tokens_full(&self, params: SemanticTokensParams) -> Result<Option<SemanticTokensResult>> {
    let uri = params.text_document.uri;
    
    let db = self.db.lock().unwrap();
    let tokens = db.semantic_tokens(uri);
    drop(db);
    
    Ok(Some(SemanticTokensResult::Tokens(SemanticTokens {
        result_id: None,
        data: tokens.to_vec(),
    })))
}
```

**Deliverable**: Basic LSP features work with Salsa

---

## Phase 3: Cross-File Features (Week 2, Days 1-3)

### 3.1 Implement "Find All References" (Project-Wide)

**File**: `crates/windjammer-lsp/src/references.rs` (new)

```rust
pub fn find_all_references(
    db: &dyn LanguageQueries,
    symbol_uri: Url,
    symbol_name: &str,
) -> Vec<Location> {
    let mut references = Vec::new();
    
    // Get all files that transitively import this file
    let dependent_files = find_dependent_files(db, &symbol_uri);
    
    // Search each file for references
    for file_uri in dependent_files {
        let program = db.parse(file_uri.clone());
        
        for reference in find_references_in_program(&program, symbol_name) {
            references.push(Location {
                uri: file_uri.clone(),
                range: reference.range,
            });
        }
    }
    
    references
}

// Salsa query: find all files that import this file (directly or indirectly)
#[salsa::query_group(DependencyStorage)]
pub trait DependencyQueries: LanguageQueries {
    fn dependent_files(&self, uri: Url) -> Arc<Vec<Url>>;
}

fn dependent_files(db: &dyn DependencyQueries, uri: Url) -> Arc<Vec<Url>> {
    let mut dependents = Vec::new();
    
    // Iterate all known files
    for known_uri in db.all_files() {
        let imports = db.imports(known_uri.clone());
        if imports.contains(&uri) {
            dependents.push(known_uri.clone());
            
            // Recursively find files that import this one
            let transitive = db.dependent_files(known_uri);
            dependents.extend(transitive.iter().cloned());
        }
    }
    
    Arc::new(dependents)
}
```

### 3.2 Implement "Rename Symbol" (Project-Wide)

**File**: `crates/windjammer-lsp/src/rename.rs` (new)

```rust
pub fn rename_symbol(
    db: &dyn LanguageQueries,
    uri: Url,
    position: Position,
    new_name: String,
) -> Result<WorkspaceEdit> {
    // Find symbol at position
    let program = db.parse(uri.clone());
    let symbol = find_symbol_at_position(&program, position)?;
    
    // Find all references (cross-file!)
    let references = find_all_references(db, uri, &symbol.name);
    
    // Build edits for each reference
    let mut changes = HashMap::new();
    for location in references {
        changes
            .entry(location.uri)
            .or_insert_with(Vec::new)
            .push(TextEdit {
                range: location.range,
                new_text: new_name.clone(),
            });
    }
    
    Ok(WorkspaceEdit {
        changes: Some(changes),
        ..Default::default()
    })
}
```

### 3.3 Implement "Go to Definition" (Cross-File)

```rust
pub fn goto_definition(
    db: &dyn LanguageQueries,
    uri: Url,
    position: Position,
) -> Option<Location> {
    let program = db.parse(uri.clone());
    let symbol = find_symbol_at_position(&program, position)?;
    
    // Check if defined in this file
    if let Some(def_location) = find_definition_in_program(&program, &symbol.name) {
        return Some(Location {
            uri: uri.clone(),
            range: def_location,
        });
    }
    
    // Search imported files
    let imports = db.imports(uri);
    for import_uri in imports.iter() {
        let import_program = db.parse(import_uri.clone());
        if let Some(def_location) = find_definition_in_program(&import_program, &symbol.name) {
            return Some(Location {
                uri: import_uri.clone(),
                range: def_location,
            });
        }
    }
    
    None
}
```

**Deliverable**: Cross-file refactoring works

---

## Phase 4: Performance Optimization (Week 2, Days 4-5)

### 4.1 Add Incremental Parsing

**Option A**: Integrate tree-sitter for incremental parsing

```rust
use tree_sitter::{Parser, Tree};

#[salsa::query_group(IncrementalParseStorage)]
pub trait IncrementalParseQueries: salsa::Database {
    #[salsa::input]
    fn source_text_with_version(&self, uri: Url) -> (Arc<String>, usize);
    
    fn parse_tree(&self, uri: Url) -> Arc<Tree>;
}

fn parse_tree(db: &dyn IncrementalParseQueries, uri: Url) -> Arc<Tree> {
    let (source, version) = db.source_text_with_version(uri);
    
    // Try to get previous tree for incremental parsing
    let previous_tree = db.lookup_parse_tree(uri.clone());
    
    let mut parser = Parser::new();
    parser.set_language(tree_sitter_windjammer::language()).unwrap();
    
    let tree = if let Some(old_tree) = previous_tree {
        // Incremental parse!
        parser.parse(&source, Some(&old_tree))
    } else {
        // Full parse
        parser.parse(&source, None)
    }.unwrap();
    
    Arc::new(tree)
}
```

**Option B**: Implement incremental parsing in Windjammer parser

```rust
// Track edit positions and only re-parse affected nodes
pub fn incremental_parse(
    old_program: &Program,
    old_text: &str,
    edit: &Edit,
    new_text: &str,
) -> Program {
    // Find affected nodes
    let affected_range = find_affected_range(old_program, edit);
    
    // Re-parse only affected range
    let new_nodes = parse_range(new_text, affected_range);
    
    // Merge with unchanged nodes
    merge_programs(old_program, new_nodes, affected_range)
}
```

### 4.2 Optimize Query Granularity

```rust
// Instead of one big "parse" query, split into smaller queries

#[salsa::query_group(GranularParseStorage)]
pub trait GranularParseQueries: salsa::Database {
    // Parse individual functions (more granular memoization)
    fn parse_function(&self, uri: Url, function_name: String) -> Arc<Function>;
    
    // Parse individual structs
    fn parse_struct(&self, uri: Url, struct_name: String) -> Arc<Struct>;
}

// Now changing one function doesn't invalidate parsing of other functions!
```

### 4.3 Add Memory Management

```rust
impl WindjammerDatabase {
    pub fn gc(&mut self) {
        // Salsa provides automatic GC
        self.sweep_all(SweepStrategy::default());
    }
    
    pub fn set_max_memory(&mut self, max_bytes: usize) {
        // Implement custom eviction policy
        if self.memory_usage() > max_bytes {
            self.gc();
        }
    }
}
```

**Deliverable**: Sub-5ms response times on large files

---

## Phase 5: Testing & Benchmarking (Week 3, Days 1-3)

### 5.1 Create Test Suite

**File**: `crates/windjammer-lsp/tests/salsa_integration_test.rs`

```rust
#[test]
fn test_incremental_parsing() {
    let mut db = WindjammerDatabase::default();
    
    // Initial parse
    let uri = Url::parse("file:///test.wj").unwrap();
    db.set_source_text(uri.clone(), Arc::new("fn foo() { }".to_string()));
    
    let program1 = db.parse(uri.clone());
    assert_eq!(program1.items.len(), 1);
    
    // Change text
    db.set_source_text(uri.clone(), Arc::new("fn foo() { }\nfn bar() { }".to_string()));
    
    // Should recompute quickly
    let start = Instant::now();
    let program2 = db.parse(uri.clone());
    let elapsed = start.elapsed();
    
    assert_eq!(program2.items.len(), 2);
    assert!(elapsed < Duration::from_millis(5), "Incremental parse too slow: {:?}", elapsed);
}

#[test]
fn test_cross_file_dependencies() {
    let mut db = WindjammerDatabase::default();
    
    // File A
    let uri_a = Url::parse("file:///a.wj").unwrap();
    db.set_source_text(uri_a.clone(), Arc::new("pub fn foo() { }".to_string()));
    
    // File B imports A
    let uri_b = Url::parse("file:///b.wj").unwrap();
    db.set_source_text(uri_b.clone(), Arc::new("use ./a\nfn bar() { a.foo() }".to_string()));
    
    // Type check B (should succeed)
    let result_b = db.type_check(uri_b.clone());
    assert!(result_b.errors.is_empty());
    
    // Change A (rename foo to baz)
    db.set_source_text(uri_a.clone(), Arc::new("pub fn baz() { }".to_string()));
    
    // Type check B should now fail (a.foo doesn't exist)
    let result_b2 = db.type_check(uri_b.clone());
    assert!(!result_b2.errors.is_empty());
}
```

### 5.2 Create Benchmarks

**File**: `crates/windjammer-lsp/benches/salsa_benchmark.rs`

```rust
fn bench_incremental_vs_full_parse(c: &mut Criterion) {
    let mut db = WindjammerDatabase::default();
    let uri = Url::parse("file:///large.wj").unwrap();
    
    // Large file (2000 lines)
    let large_file = generate_large_file(2000);
    db.set_source_text(uri.clone(), Arc::new(large_file.clone()));
    
    // Initial parse
    db.parse(uri.clone());
    
    // Modify one line
    let modified = large_file.replace("fn test1()", "fn test1_modified()");
    
    c.bench_function("incremental_parse_2000_lines", |b| {
        b.iter(|| {
            db.set_source_text(uri.clone(), Arc::new(modified.clone()));
            db.parse(uri.clone())
        })
    });
}

fn bench_cross_file_analysis(c: &mut Criterion) {
    let mut db = WindjammerDatabase::default();
    
    // Create 100 files with imports
    for i in 0..100 {
        let uri = Url::parse(&format!("file:///file{}.wj", i)).unwrap();
        let content = if i == 0 {
            "pub fn root() { }".to_string()
        } else {
            format!("use ./file{}\nfn func{}() {{ }}", i - 1, i)
        };
        db.set_source_text(uri, Arc::new(content));
    }
    
    let last_uri = Url::parse("file:///file99.wj").unwrap();
    
    c.bench_function("cross_file_analysis_100_files", |b| {
        b.iter(|| db.type_check(last_uri.clone()))
    });
}
```

### 5.3 Stress Testing

**File**: `crates/windjammer-lsp/tests/stress_test.rs`

```rust
#[test]
fn stress_test_rapid_edits() {
    let mut db = WindjammerDatabase::default();
    let uri = Url::parse("file:///test.wj").unwrap();
    
    // Simulate user typing rapidly
    let mut content = String::new();
    for i in 0..1000 {
        content.push_str(&format!("fn func{}() {{ }}\n", i));
        db.set_source_text(uri.clone(), Arc::new(content.clone()));
        
        // Each edit should be fast
        let start = Instant::now();
        let _ = db.diagnostics(uri.clone());
        let elapsed = start.elapsed();
        
        assert!(elapsed < Duration::from_millis(50), "Edit {} too slow: {:?}", i, elapsed);
    }
}
```

**Deliverable**: All tests pass, benchmarks show 10-100x speedup

---

## Phase 6: Documentation (Week 3, Days 4-5)

### 6.1 Architecture Documentation

**File**: `docs/LSP_ARCHITECTURE.md`

```markdown
# Windjammer LSP Architecture

## Overview

The Windjammer LSP uses Salsa for incremental computation, providing fast,
responsive language features.

## Query Structure

```
source_text (input)
    ↓
parse (derived, memoized)
    ↓
imports (derived, memoized)
    ↓
type_check (derived, memoized)
    ↓
[diagnostics, semantic_tokens, hover, etc.]
```

## Incremental Updates

When source text changes:
1. Salsa marks the `source_text` query as changed
2. Dependent queries (`parse`, `type_check`) are invalidated
3. On next request, only changed queries recompute
4. Unchanged results return cached values

## Cross-File Analysis

Files depend on each other through imports:
- Changing file A invalidates files B, C that import A
- Salsa tracks these dependencies automatically
- Transitive dependencies handled correctly

## Performance

- Small edits: 1-5ms
- Large files (>2000 lines): 10-20ms
- Cross-file updates: 20-50ms
- Memory usage: O(file_count)
```

### 6.2 Migration Guide

**File**: `docs/LSP_MIGRATION.md`

```markdown
# Migrating from v0.23.0 to v0.24.0 LSP

## What Changed

v0.24.0 introduces Salsa-based incremental computation for the LSP.

## Breaking Changes

**None for end users!** The LSP protocol is unchanged.

## Performance Improvements

| Feature | v0.23.0 | v0.24.0 | Improvement |
|---------|---------|---------|-------------|
| Small file edit | 10-20ms | 1-5ms | **4-20x faster** |
| Large file edit | 100ms+ | 10-20ms | **5-10x faster** |
| Cross-file rename | N/A | 50ms | **New feature!** |

## New Features

### Find All References (Project-Wide)

Now works across files!

```
Cmd+Shift+F12 (VS Code)
```

### Rename Symbol (Project-Wide)

Renames across all files that reference the symbol.

```
F2 (VS Code)
```

### Go to Definition (Cross-File)

Jumps to definitions in imported files.

```
F12 (VS Code)
```

## Configuration

No configuration changes needed.

## Troubleshooting

If LSP feels slow:
1. Check number of open files (>100 may be slow)
2. Check file sizes (>5000 lines may be slow)
3. Report performance issues with `wj lsp --profile`
```

### 6.3 API Documentation

**File**: `crates/windjammer-lsp/src/lib.rs`

```rust
//! Windjammer Language Server Protocol (LSP) Implementation
//!
//! This crate provides a Language Server Protocol implementation for Windjammer,
//! enabling IDE features like autocomplete, diagnostics, and refactoring.
//!
//! # Architecture
//!
//! The LSP uses [Salsa](https://github.com/salsa-rs/salsa) for incremental
//! computation, providing fast, responsive language features even on large codebases.
//!
//! ## Query Structure
//!
//! ```text
//! source_text (input)
//!     ↓
//! parse (derived, memoized)
//!     ↓
//! imports (derived, memoized)
//!     ↓
//! type_check (derived, memoized)
//!     ↓
//! [diagnostics, semantic_tokens, hover, etc.]
//! ```
//!
//! ## Example Usage
//!
//! ```no_run
//! use windjammer_lsp::WindjammerLanguageServer;
//! use tower_lsp::{LspService, Server};
//!
//! #[tokio::main]
//! async fn main() {
//!     let (service, socket) = LspService::new(|client| {
//!         WindjammerLanguageServer::new(client)
//!     });
//!    
//!     Server::new(tokio::io::stdin(), tokio::io::stdout(), socket)
//!         .serve(service)
//!         .await;
//! }
//! ```
```

**Deliverable**: Complete documentation for Salsa integration

---

## Success Criteria

### Performance Targets

- ✅ **Small file edits (<500 lines)**: < 5ms
- ✅ **Large file edits (>2000 lines)**: < 20ms
- ✅ **Cross-file updates**: < 50ms
- ✅ **Memory usage**: < 100MB for 1000 files

### Feature Completeness

- ✅ **Find All References** (project-wide)
- ✅ **Rename Symbol** (project-wide)
- ✅ **Go to Definition** (cross-file)
- ✅ **Incremental parsing** (10x speedup)
- ✅ **Smart caching** (automatic invalidation)

### Code Quality

- ✅ **100% test coverage** for Salsa queries
- ✅ **Benchmarks** showing 10-100x speedup
- ✅ **Documentation** for all public APIs
- ✅ **No clippy warnings**

---

## Timeline

| Week | Days | Tasks | Deliverable |
|------|------|-------|-------------|
| **Week 1** | 1-3 | Foundation: Add Salsa, design queries, implement basic queries | Salsa database compiles |
| **Week 1** | 4-5 | Integration: Update server, handlers, LSP features | Basic LSP works with Salsa |
| **Week 2** | 1-3 | Cross-file: Find references, rename, go-to-definition | Cross-file refactoring works |
| **Week 2** | 4-5 | Performance: Incremental parsing, query optimization | Sub-5ms response times |
| **Week 3** | 1-3 | Testing: Integration tests, benchmarks, stress tests | All tests pass, 10-100x speedup |
| **Week 3** | 4-5 | Documentation: Architecture, migration guide, API docs | Complete documentation |

**Total: 15 working days (3 weeks)**

---

## Risk Mitigation

### Risk 1: Salsa Learning Curve

**Mitigation**: 
- Study rust-analyzer source code (best example)
- Read Salsa documentation thoroughly
- Start with simple queries, iterate to complex

### Risk 2: Integration Breaking Existing Features

**Mitigation**:
- Keep old implementation alongside new one
- A/B test both implementations
- Only switch when Salsa version is stable

### Risk 3: Performance Not Meeting Targets

**Mitigation**:
- Benchmark early and often
- Profile with `perf` to find bottlenecks
- Consider incremental parsing (tree-sitter)

### Risk 4: Cross-File Analysis Too Slow

**Mitigation**:
- Limit to 100 files by default
- Add configuration for max files
- Implement background indexing

---

## Dependencies

### New Crates

```toml
[dependencies]
salsa = "0.17"  # Incremental computation framework
tree-sitter = "0.20"  # Optional: for incremental parsing
tree-sitter-windjammer = { path = "../tree-sitter-windjammer" }  # Optional
```

### Build Time Impact

- Salsa compilation: +30s first build
- Incremental builds: +2s
- LSP binary size: +500KB

---

## Rollout Plan

### v0.24.0-alpha.1 (Week 1)

- Foundation complete
- Basic queries working
- Not user-facing yet

### v0.24.0-beta.1 (Week 2)

- Cross-file features working
- Performance optimized
- Early adopters can test

### v0.24.0-rc.1 (Week 3)

- All tests passing
- Documentation complete
- Ready for release candidate testing

### v0.24.0 (Release)

- Production-ready
- All features validated
- Performance targets met

---

## Post-Release Tasks

### v0.24.1 (Bug Fixes)

- Fix any issues found in v0.24.0
- Performance tuning based on user feedback
- Memory usage optimization

### v0.25.0 (Advanced Features)

- Code actions (quick fixes)
- Inlay hints (type annotations)
- Call hierarchy
- Document outline improvements

---

## Appendix: Salsa Resources

1. **Official Docs**: https://github.com/salsa-rs/salsa
2. **Rust Analyzer**: Best real-world example
3. **Chalk**: Rust trait solver using Salsa
4. **Book**: "Salsa: Incremental Computation in Rust" (online)

---

**Status**: ✅ **PLAN COMPLETE - READY TO START**  
**Next Step**: Create v0.24.0 branch and begin Week 1, Days 1-3  
**User Approval**: REQUESTED

